{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network 1D normal distribution Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 실습은 딥러닝 라이브러리 PyTorch를 기반으로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습에 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import cufflinks as cf\n",
    "import plotly\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch가 GPU를 통해 연산을 하는지 확인하기( True가 나올 때, 연산은 GPU에서 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 결과를 저장할 폴더 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"D:\\\\PROJECT\\\\2019_Education_DL\\\\GAN\\\\\"\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Input과 관련한 함수들을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규분포(mu, sigma)에서 n개의 sample 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0과 1사이의 숫자를 임의로 생성 - 정규분포가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator class 생성- PyTorch의 대부분은 class method로 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        \n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrminator class 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기타 필요한 함수들 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d):\n",
    "    return [round(np.mean(d), 4), round(np.std(d), 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_with_diffs(data, exponent):\n",
    "\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0])\n",
    "\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperparameter 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> 생성하고자 하는 1D Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 4\n",
    "data_stddev = 1.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> Generator Network 구조 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector : (1,N)\n",
    "g_hidden_size = 50   # G의 레이어 크기\n",
    "g_output_size = 1    # G의 결과값의 크기 : (1,N) - 위조 지폐의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> Discriminator Network 구조 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # D의 레이어 크기\n",
    "d_output_size = 1    # 진짜인지 가짜인지의 여부(확률값) : (1,1)\n",
    "minibatch_size = d_input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> Generator/ Discriminator Sample 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi_sampler = get_generator_input_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps,g_steps = 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> d_learning_rate : Discriminator 학습율 지정/ g_learning_rate : Generator 학습율 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> 해당 값들을 너무 크게 지정하거나, 너무 작게 지정하면 학습에 문제가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(크게 지정한 경우:학습이 되지 않는 상황 발생/ 작게 지정한 경우 : 학습 속도가 매우 더딤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> Epoch 수 지정 및 결과 횟수 간격 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2400 # 얼마나 최적화할지\n",
    "print_interval = 10 # 몇번마다 결과를 출력할지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> Generator/ Discriminator Network Instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------> 진짜 데이터이냐, 가짜 데이터(생성된 데이터)냐? = 2개의 Class를 분류하는 Classification 모델 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------> Optimizer를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------> 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if 'img' not in os.listdir():\n",
    "        os.mkdir(\"img\")\n",
    "        \n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: 실제 데이터로 D 학습\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: 가짜 데이터로 D 학습\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "\n",
    "        # 2. D의 반응에 따라 G학습\n",
    "\n",
    "        # G 초기화\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if (epoch+1) % (print_interval*10) == 0:\n",
    "        print(\"%s: D: %.4f/%.4f G: %.4f (Real: %s, Fake: %s) \\n\" % (epoch+1,\n",
    "                                                            round(extract(d_real_error)[0],4),\n",
    "                                                            round(extract(d_fake_error)[0],4),\n",
    "                                                            round(extract(g_error)[0],4),\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))\n",
    "                                                                   )\n",
    "             )\n",
    "    if (epoch+1) % print_interval == 0:\n",
    "        [mu_real, sigma_real] = stats(extract(d_real_data))\n",
    "        [mu_fake, sigma_fake] = stats(extract(d_fake_data))\n",
    "\n",
    "        x1 = np.linspace(mu_real-9*sigma_real,mu_real+9*sigma_real, 100)\n",
    "        x2 = np.linspace(mu_fake-9*sigma_fake,mu_real+9*sigma_fake, 100)\n",
    "        plt.plot(x1,mlab.normpdf(x1, mu_real, sigma_real))\n",
    "        plt.plot(x2,mlab.normpdf(x2, mu_fake, sigma_fake))\n",
    "        plt.title('Generate 1D Gaussian Distribution using GAN: %7d epoch'%(epoch+1))\n",
    "        plt.xlabel('Data values')\n",
    "        plt.ylabel('Probability density')\n",
    "        plt.savefig('img/Generate 1D Gaussian Distribution using GAN: %7d epoch'%(epoch+1) + '.png',dpi=200)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
