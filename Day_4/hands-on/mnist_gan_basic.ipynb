{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch size 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root = './mnist_data/', train = True, transform = transform, download = True)\n",
    "test_data = datasets.MNIST(root = './mnist_data/', train = False, transform = transform, download = False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./mnist_data/\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c1dff88358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.train_data.numpy()[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dim = train_data.train_data.size(1) * train_data.train_data.size(2)\n",
    "mnist_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(mnist_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "G_optim = optim.Adam(G.parameters(), lr = lr)\n",
    "D_optim = optim.Adam(D.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_train(x):\n",
    "    D.zero_grad()\n",
    "\n",
    "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(batch_size, 1)\n",
    "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
    "\n",
    "    D_output = D(x_real)\n",
    "    D_real_loss = criterion(D_output, y_real)\n",
    "    D_real_score = D_output\n",
    "\n",
    "    z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
    "    x_fake, y_fake = G(z), Variable(torch.zeros(batch_size, 1).to(device))\n",
    "\n",
    "    D_output = D(x_fake)\n",
    "    D_fake_loss = criterion(D_output, y_fake)\n",
    "    D_fake_score = D_output\n",
    "\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optim.step()\n",
    "\n",
    "    return D_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_train(x):\n",
    "    G.zero_grad()\n",
    "\n",
    "    z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
    "    y = Variable(torch.ones(batch_size, 1).to(device))\n",
    "\n",
    "    G_output = G(z)\n",
    "    D_output = D(G_output)\n",
    "    G_loss = criterion(D_output, y)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_optim.step()\n",
    "\n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]: loss_d: 0.159, loss_g: 5.410\n",
      "[1/100]: loss_d: 0.175, loss_g: 5.111\n",
      "[1/100]: loss_d: 0.211, loss_g: 4.816\n",
      "[1/100]: loss_d: 0.243, loss_g: 4.587\n",
      "[1/100]: loss_d: 0.252, loss_g: 4.502\n",
      "[1/100]: loss_d: 0.247, loss_g: 4.617\n",
      "[1/100]: loss_d: 0.246, loss_g: 4.698\n",
      "[1/100]: loss_d: 0.236, loss_g: 4.712\n",
      "[1/100]: loss_d: 0.235, loss_g: 4.657\n",
      "[1/100]: loss_d: 0.236, loss_g: 4.566\n",
      "[1/100]: loss_d: 0.246, loss_g: 4.484\n",
      "[1/100]: loss_d: 0.270, loss_g: 4.438\n",
      "[1/100]: loss_d: 0.276, loss_g: 4.389\n",
      "[1/100]: loss_d: 0.284, loss_g: 4.322\n",
      "[1/100]: loss_d: 0.296, loss_g: 4.241\n",
      "[1/100]: loss_d: 0.301, loss_g: 4.167\n",
      "[1/100]: loss_d: 0.308, loss_g: 4.143\n",
      "[1/100]: loss_d: 0.309, loss_g: 4.137\n",
      "[1/100]: loss_d: 0.309, loss_g: 4.128\n",
      "[1/100]: loss_d: 0.312, loss_g: 4.108\n",
      "[1/100]: loss_d: 0.319, loss_g: 4.105\n",
      "[1/100]: loss_d: 0.318, loss_g: 4.069\n",
      "[1/100]: loss_d: 0.320, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.014\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.321, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.321, loss_g: 3.997\n",
      "[1/100]: loss_d: 0.320, loss_g: 3.998\n",
      "[1/100]: loss_d: 0.320, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.317, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.312, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.313, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.312, loss_g: 4.006\n",
      "[1/100]: loss_d: 0.313, loss_g: 3.995\n",
      "[1/100]: loss_d: 0.308, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.305, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.305, loss_g: 4.069\n",
      "[1/100]: loss_d: 0.306, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.307, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.307, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.308, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.310, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.309, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.310, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.311, loss_g: 4.010\n",
      "[1/100]: loss_d: 0.311, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.314, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.317, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.315, loss_g: 4.007\n",
      "[1/100]: loss_d: 0.317, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.314, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.313, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.313, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.314, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.318, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.317, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.321, loss_g: 4.051\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.006\n",
      "[1/100]: loss_d: 0.334, loss_g: 3.995\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.004\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.009\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.003\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.071\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.063\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.056\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.067\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.087\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.099\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.093\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.082\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.078\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.083\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.088\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.095\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.099\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.100\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.101\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.098\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.099\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.100\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.109\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.115\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.111\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.106\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.100\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.100\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.101\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.101\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.098\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.088\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.078\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.078\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.072\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.062\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.053\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.053\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.060\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.070\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.076\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.074\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.071\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.076\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.087\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.093\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.088\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.081\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.075\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.071\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.074\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.081\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.085\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.085\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.077\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.077\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.087\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.101\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.107\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.106\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.103\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.104\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.110\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.119\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.127\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.127\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.121\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.114\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.116\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.115\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.112\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.109\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.104\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.102\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.100\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.096\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.092\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.085\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.082\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.076\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.077\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.079\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.076\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.070\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.063\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.058\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.050\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.050\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.050\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.013\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.013\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.014\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.009\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.346, loss_g: 3.995\n",
      "[1/100]: loss_d: 0.346, loss_g: 3.995\n",
      "[1/100]: loss_d: 0.347, loss_g: 3.995\n",
      "[1/100]: loss_d: 0.348, loss_g: 3.990\n",
      "[1/100]: loss_d: 0.349, loss_g: 3.981\n",
      "[1/100]: loss_d: 0.349, loss_g: 3.976\n",
      "[1/100]: loss_d: 0.349, loss_g: 3.976\n",
      "[1/100]: loss_d: 0.350, loss_g: 3.977\n",
      "[1/100]: loss_d: 0.351, loss_g: 3.976\n",
      "[1/100]: loss_d: 0.352, loss_g: 3.972\n",
      "[1/100]: loss_d: 0.353, loss_g: 3.964\n",
      "[1/100]: loss_d: 0.354, loss_g: 3.957\n",
      "[1/100]: loss_d: 0.355, loss_g: 3.954\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.953\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.951\n",
      "[1/100]: loss_d: 0.357, loss_g: 3.946\n",
      "[1/100]: loss_d: 0.358, loss_g: 3.942\n",
      "[1/100]: loss_d: 0.358, loss_g: 3.939\n",
      "[1/100]: loss_d: 0.358, loss_g: 3.940\n",
      "[1/100]: loss_d: 0.358, loss_g: 3.942\n",
      "[1/100]: loss_d: 0.357, loss_g: 3.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]: loss_d: 0.357, loss_g: 3.939\n",
      "[1/100]: loss_d: 0.357, loss_g: 3.936\n",
      "[1/100]: loss_d: 0.357, loss_g: 3.936\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.937\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.938\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.939\n",
      "[1/100]: loss_d: 0.356, loss_g: 3.938\n",
      "[1/100]: loss_d: 0.355, loss_g: 3.936\n",
      "[1/100]: loss_d: 0.355, loss_g: 3.936\n",
      "[1/100]: loss_d: 0.354, loss_g: 3.937\n",
      "[1/100]: loss_d: 0.353, loss_g: 3.941\n",
      "[1/100]: loss_d: 0.352, loss_g: 3.944\n",
      "[1/100]: loss_d: 0.351, loss_g: 3.947\n",
      "[1/100]: loss_d: 0.350, loss_g: 3.950\n",
      "[1/100]: loss_d: 0.350, loss_g: 3.952\n",
      "[1/100]: loss_d: 0.349, loss_g: 3.956\n",
      "[1/100]: loss_d: 0.348, loss_g: 3.957\n",
      "[1/100]: loss_d: 0.348, loss_g: 3.958\n",
      "[1/100]: loss_d: 0.347, loss_g: 3.959\n",
      "[1/100]: loss_d: 0.346, loss_g: 3.961\n",
      "[1/100]: loss_d: 0.345, loss_g: 3.965\n",
      "[1/100]: loss_d: 0.345, loss_g: 3.968\n",
      "[1/100]: loss_d: 0.344, loss_g: 3.972\n",
      "[1/100]: loss_d: 0.344, loss_g: 3.973\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.977\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.981\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.986\n",
      "[1/100]: loss_d: 0.344, loss_g: 3.989\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.991\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.996\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.997\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.998\n",
      "[1/100]: loss_d: 0.343, loss_g: 3.998\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.002\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.003\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.345, loss_g: 3.998\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.003\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.003\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.003\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.000\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.002\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.005\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.005\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.006\n",
      "[1/100]: loss_d: 0.347, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.347, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.346, loss_g: 4.007\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.007\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.007\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.005\n",
      "[1/100]: loss_d: 0.345, loss_g: 4.005\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.006\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.009\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.010\n",
      "[1/100]: loss_d: 0.344, loss_g: 4.010\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.343, loss_g: 4.008\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.010\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.013\n",
      "[1/100]: loss_d: 0.342, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.010\n",
      "[1/100]: loss_d: 0.341, loss_g: 4.011\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.340, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.016\n",
      "[1/100]: loss_d: 0.339, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.014\n",
      "[1/100]: loss_d: 0.338, loss_g: 4.012\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.337, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.336, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.335, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.334, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.333, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.020\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.051\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.060\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.058\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.059\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.065\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.056\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.060\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.056\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.332, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.031\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]: loss_d: 0.327, loss_g: 4.019\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.019\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.023\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.031\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.032\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.322, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.323, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.034\n",
      "[1/100]: loss_d: 0.324, loss_g: 4.035\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.325, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.024\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.020\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.020\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.019\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.016\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.016\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.015\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.013\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.013\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.016\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.017\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.018\n",
      "[1/100]: loss_d: 0.331, loss_g: 4.019\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.020\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.021\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.022\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.330, loss_g: 4.025\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.026\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.027\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.028\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.029\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.030\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.033\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.036\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.037\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.044\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.047\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.053\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.056\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.058\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.059\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.062\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.065\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.064\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.063\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.060\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.061\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.060\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.057\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.055\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.054\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.052\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.051\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.049\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.048\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.046\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.045\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.043\n",
      "[1/100]: loss_d: 0.329, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.328, loss_g: 4.039\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.038\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.040\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.327, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.042\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.041\n",
      "[1/100]: loss_d: 0.326, loss_g: 4.040\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-fc8cab463118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtest_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mgenerated_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msave_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sample_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_image' is not defined"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "for e in range(1, n_epoch+1):\n",
    "    D_losses, G_losses = [], []\n",
    "    \n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        D_losses.append(D_train(x))\n",
    "        G_losses.append(G_train(x))\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "                (e), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
    "        \n",
    "    test_z = Variable(torch.randn(1, z_dim).to(device))\n",
    "    generated_samples = G(test_z)\n",
    "    save_image(generated_samples.view(generated_samples.size(0),1,28,28), 'sample_'+str(e)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
