{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "viz_filter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E8Pd8EZeNI0",
        "colab_type": "text"
      },
      "source": [
        "모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neADRdPodz5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Created on Sat Nov 18 23:12:08 2017\n",
        "@author: Utku Ozbulak - github.com/utkuozbulak\n",
        "\"\"\"\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbIQ3RoreQ2_",
        "colab_type": "text"
      },
      "source": [
        "유틸함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HOndup3eCQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recreate_image(im_as_var):\n",
        "    \"\"\"\n",
        "        Recreates images from a torch variable, sort of reverse preprocessing\n",
        "    Args:\n",
        "        im_as_var (torch variable): Image to recreate\n",
        "    returns:\n",
        "        recreated_im (numpy arr): Recreated image in array\n",
        "    \"\"\"\n",
        "    reverse_mean = [-0.485, -0.456, -0.406]\n",
        "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
        "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
        "    for c in range(3):\n",
        "        recreated_im[c] /= reverse_std[c]\n",
        "        recreated_im[c] -= reverse_mean[c]\n",
        "    recreated_im[recreated_im > 1] = 1\n",
        "    recreated_im[recreated_im < 0] = 0\n",
        "    recreated_im = np.round(recreated_im * 255)\n",
        "\n",
        "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
        "    return recreated_im\n",
        "  \n",
        "\n",
        "def format_np_output(np_arr):\n",
        "    \"\"\"\n",
        "        This is a (kind of) bandaid fix to streamline saving procedure.\n",
        "        It converts all the outputs to the same format which is 3xWxH\n",
        "        with using sucecssive if clauses.\n",
        "    Args:\n",
        "        im_as_arr (Numpy array): Matrix of shape 1xWxH or WxH or 3xWxH\n",
        "    \"\"\"\n",
        "    # Phase/Case 1: The np arr only has 2 dimensions\n",
        "    # Result: Add a dimension at the beginning\n",
        "    if len(np_arr.shape) == 2:\n",
        "        np_arr = np.expand_dims(np_arr, axis=0)\n",
        "    # Phase/Case 2: Np arr has only 1 channel (assuming first dim is channel)\n",
        "    # Result: Repeat first channel and convert 1xWxH to 3xWxH\n",
        "    if np_arr.shape[0] == 1:\n",
        "        np_arr = np.repeat(np_arr, 3, axis=0)\n",
        "    # Phase/Case 3: Np arr is of shape 3xWxH\n",
        "    # Result: Convert it to WxHx3 in order to make it saveable by PIL\n",
        "    if np_arr.shape[0] == 3:\n",
        "        np_arr = np_arr.transpose(1, 2, 0)\n",
        "    # Phase/Case 4: NP arr is normalized between 0-1\n",
        "    # Result: Multiply with 255 and change type to make it saveable by PIL\n",
        "    if np.max(np_arr) <= 1:\n",
        "        np_arr = (np_arr*255).astype(np.uint8)\n",
        "    return np_arr\n",
        "\n",
        "\n",
        "def save_image(im, path):\n",
        "    \"\"\"\n",
        "        Saves a numpy matrix or PIL image as an image\n",
        "    Args:\n",
        "        im_as_arr (Numpy array): Matrix of shape DxWxH\n",
        "        path (str): Path to the image\n",
        "    \"\"\"\n",
        "    if isinstance(im, (np.ndarray, np.generic)):\n",
        "        im = format_np_output(im)\n",
        "        im = Image.fromarray(im)\n",
        "    im.save(path)\n",
        "\n",
        "\n",
        "def preprocess_image(pil_im, resize_im=True):\n",
        "    \"\"\"\n",
        "        Processes image for CNNs\n",
        "    Args:\n",
        "        PIL_img (PIL_img): Image to process\n",
        "        resize_im (bool): Resize to 224 or not\n",
        "    returns:\n",
        "        im_as_var (torch variable): Variable that contains processed float tensor\n",
        "    \"\"\"\n",
        "    # mean and std list for channels (Imagenet)\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    # Resize image\n",
        "    if resize_im:\n",
        "        pil_im.thumbnail((512, 512))\n",
        "    im_as_arr = np.float32(pil_im)\n",
        "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
        "    # Normalize the channels\n",
        "    for channel, _ in enumerate(im_as_arr):\n",
        "        im_as_arr[channel] /= 255\n",
        "        im_as_arr[channel] -= mean[channel]\n",
        "        im_as_arr[channel] /= std[channel]\n",
        "    # Convert to float tensor\n",
        "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
        "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
        "    im_as_ten.unsqueeze_(0)\n",
        "    # Convert to Pytorch variable\n",
        "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
        "    return im_as_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4IuU0JSeW1Y",
        "colab_type": "text"
      },
      "source": [
        "필터 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6noGYGB-eLp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLayerVisualization():\n",
        "    \"\"\"\n",
        "        Produces an image that minimizes the loss of a convolution\n",
        "        operation for a specific layer and filter\n",
        "    \"\"\"\n",
        "    def __init__(self, model, selected_layer, selected_filter):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.selected_layer = selected_layer\n",
        "        self.selected_filter = selected_filter\n",
        "        self.conv_output = 0\n",
        "        # Create the folder to export images if not exists\n",
        "        if not os.path.exists('../generated'):\n",
        "            os.makedirs('../generated')\n",
        "\n",
        "    def hook_layer(self):\n",
        "        def hook_function(module, grad_in, grad_out):\n",
        "            # Gets the conv output of the selected filter (from selected layer)\n",
        "            self.conv_output = grad_out[0, self.selected_filter]\n",
        "        # Hook the selected layer\n",
        "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
        "\n",
        "    def visualise_layer_with_hooks(self):\n",
        "        # Hook the selected layer\n",
        "        self.hook_layer()\n",
        "        # Generate a random image\n",
        "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
        "        # Process image and return variable\n",
        "        processed_image = preprocess_image(random_image, False)\n",
        "        # Define optimizer for the image\n",
        "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
        "        for i in range(1, 31):\n",
        "            optimizer.zero_grad()\n",
        "            # Assign create image to a variable to move forward in the model\n",
        "            x = processed_image\n",
        "            for index, layer in enumerate(self.model):\n",
        "                # Forward pass layer by layer\n",
        "                # x is not used after this point because it is only needed to trigger\n",
        "                # the forward hook function\n",
        "                x = layer(x)\n",
        "                # Only need to forward until the selected layer is reached\n",
        "                if index == self.selected_layer:\n",
        "                    # (forward hook function triggered)\n",
        "                    break\n",
        "            # Loss function is the mean of the output of the selected layer/filter\n",
        "            # We try to minimize the mean of the output of that specific filter\n",
        "            loss = -torch.mean(self.conv_output)\n",
        "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
        "            # Backward\n",
        "            loss.backward()\n",
        "            # Update image\n",
        "            optimizer.step()\n",
        "            # Recreate image\n",
        "            self.created_image = recreate_image(processed_image)\n",
        "        # Save image\n",
        "        im_path = 'vis_filter/layer_vis_l' + str(self.selected_layer) + '_f' + str(self.selected_filter) + '.jpg'\n",
        "        save_image(self.created_image, im_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ray71-7eaIZ",
        "colab_type": "text"
      },
      "source": [
        "17번째 레이어 5번째 필터 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8b3n1g0d5mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_layer = 17\n",
        "filter_pos = 5\n",
        "# Fully connected layer is not needed\n",
        "pretrained_model = models.vgg16(pretrained=True).features\n",
        "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
        "\n",
        "# Layer visualization with pytorch hooks\n",
        "layer_vis.visualise_layer_with_hooks()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}