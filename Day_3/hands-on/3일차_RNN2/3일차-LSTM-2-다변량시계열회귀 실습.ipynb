{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LSTM 실습: 다변량 시계열 예측 모델링 및 비교]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jupyter notebook 단축키\n",
    "\n",
    "- ctrl+enter: 셀 실행   \n",
    "- shift+enter: 셀 실행 및 다음 셀 이동   \n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)\n",
    "- y: Code로 변경\n",
    "- m: Markdown으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('content/gdrive/')\n",
    "import os\n",
    "os.chdir('/content/gdrove/My Drive/Day3/hands-on/3일차_RNN2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as pdr\n",
    "# pip install pandas-datareader\n",
    "\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정규화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling function for input data\n",
    "def minmax_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기\n",
    "##### Pandas Datareader 사용: 야후에서 제공하는 API사용\n",
    "#####  \n",
    "#####  \n",
    "\n",
    "- X: 주식 정보(High, Low, Open, Close, Volumne, Adj Close)\n",
    "- y: 주식 정보(High, Low, Open, Close, Volumne, Adj Close) 중 택 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at stock prices over the past year\n",
    "start = (2000, 12, 1)\n",
    "start = datetime.datetime(*start) #그냥 tuple로 넣어주면 안됨, *: 인자를 각각 순서대로 넣어줌\n",
    "end = datetime.date.today()\n",
    "\n",
    "# google = pdr.DataReader('어떤종목', '어디서', 언제부터, 언제까지)                    \n",
    "yahoo = pdr.DataReader('AAPL', 'yahoo', start, end)\n",
    "\n",
    "# 한화: 000880.KS\n",
    "# 한화 케미칼: 009830.KS\n",
    "# 한화 손해보험: 000370.KS\n",
    "# 모나미: 005360.KS\n",
    "# 하이트진로홀딩스우: 000145.KS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yahoo.head())\n",
    "# High: 장 중 제일 높았던 주가(고가)\n",
    "# Low: 장 중 제일 낮았던 주가(저가)\n",
    "# Open: 장 시작 때 주가(시가)\n",
    "# Close: 장 닫을 때 주가(종가)\n",
    "# Volume: 주식 거래량\n",
    "# Adj Close: 주식의 분할, 배당, 배분 등을 고려해 조정한 종가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yahoo.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo.Close.plot(grid=True)  # Close --> change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rvs = yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperparameters\n",
    "- seq_length: 시퀀스 길이\n",
    "- data_dim: 변수 개수\n",
    "- hidden_dim: hidden state vector 차원(=특징을 얼마나 추출하여 학습할 것인지)\n",
    "- output_dim: 학습 반복 회수\n",
    "- learning_rate: 학습률\n",
    "- iterations: 학습 반복 회수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 7    # 반영하고자 하는 날짜\n",
    "data_dim = 6      # 변수 갯수 \n",
    "hidden_dim = 10\n",
    "output_dim = 1    # 예측 변수 갯수\n",
    "learning_rate = 0.01\n",
    "iterations = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train-test set\n",
    "train_size = int(len(data_rvs) * 0.7)\n",
    "train_set = data_rvs[0:train_size]\n",
    "test_set = data_rvs[train_size - seq_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "train_set = minmax_scaler(train_set)\n",
    "test_set = minmax_scaler(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리: sequence 길이에 맞게  RNN Input 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "        _x = time_series.iloc[i:i + seq_length, :]\n",
    "        _y = time_series.iloc[i + seq_length, [3]]  # Next close price  #[3,4]: Close and volume\n",
    "        print(_x, \"->\", _y)\n",
    "        dataX.append(_x.values)\n",
    "        dataY.append(_y.values)\n",
    "    \n",
    "    return np.stack(dataX), np.stack(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind\n",
    "\n",
    "#seq_length = 7    # 반영하고자 하는 날짜\n",
    "#data_dim = 6      # 변수 갯수 \n",
    "#hidden_dim = 10\n",
    "#output_dim = 1    # 예측 변수 갯수\n",
    "#learning_rate = 0.01\n",
    "#iterations = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train-test dataset to input\n",
    "trainX, trainY = build_dataset(train_set, seq_length)\n",
    "testX, testY = build_dataset(test_set, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape) #3277,7,6\n",
    "print(trainY.shape) #3277,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape) #1408,7,6\n",
    "print(testY.shape) #1408,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LSTM & GRU 학습 및 평가: 다음 시점의 Close price 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        #self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        #self.rnn = torch.nn.GRU(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(data_dim, hidden_dim, output_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss & optimizer setting\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "for i in range(iterations):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(trainX_tensor)\n",
    "    loss = criterion(outputs, trainY_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training\n",
    "plt.plot(trainY)\n",
    "plt.plot(net(trainX_tensor).data.numpy())\n",
    "plt.legend(['original', 'prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start testing\n",
    "for i in range(iterations):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    test_outputs = net(testX_tensor)\n",
    "    loss = criterion(test_outputs, testY_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot testing\n",
    "plt.plot(testY)\n",
    "plt.plot(net(testX_tensor).data.numpy())\n",
    "plt.legend(['original', 'prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve prediction y(tensor) to numpy array\n",
    "train_predictionY = outputs.detach()\n",
    "train_predictionY = train_predictionY.numpy()\n",
    "\n",
    "test_predictionY = test_outputs.detach()\n",
    "test_predictionY = test_predictionY.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(trainY, train_predictionY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(testY, test_predictionY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN\n",
    "## Test MSE: 6.535761378376095e-05\n",
    "## Train MSE: 0.00022348110553613228\n",
    "\n",
    "\n",
    "## LSTM\n",
    "## Test MSE: 6.259012494261207e-05\n",
    "## Train MSE: 0.00019432165494639008\n",
    "\n",
    "\n",
    "## GRU\n",
    "## Test MSE: 5.0685171742773086e-05\n",
    "## Train MSE: 0.00023175848398944936\n",
    "\n",
    "#### 과대적합이 발생한 상황이다.\n",
    "#### 1. 은닉층 차원 줄이기\n",
    "#### 2. 시퀀스 길이 늘리기\n",
    "#### 3. 더 작은 학습률 적용시키기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
